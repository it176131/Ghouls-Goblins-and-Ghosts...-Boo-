{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectPercentile, mutual_info_classif, f_classif, RFE, RFECV\n",
    "\n",
    "# decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ensemble\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# process classifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "# neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# support vector machines\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# train test split, tuning, and score validation\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'AdaBoostClassifier' : AdaBoostClassifier(random_state=0),\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier(random_state=0),\n",
    "    'ExtraTreesClassifier' : ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "    'RandomForestClassifier' : RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "    'LogisticRegression' : LogisticRegression(solver='lbfgs', multi_class='auto', random_state=0, max_iter=500),\n",
    "    'GaussianNB' : GaussianNB(),\n",
    "    'GaussianProcessClassifier' : GaussianProcessClassifier(random_state=0),\n",
    "    'KNeighborsClassifier' : KNeighborsClassifier(),\n",
    "    'MLPClassifier' : MLPClassifier(random_state=0, max_iter=1500),\n",
    "    'LinearSVC' : LinearSVC(random_state=0, max_iter=2000),\n",
    "    'SVC' : SVC(gamma='scale', random_state=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ensembles = {\n",
    "    'AdaBoostClassifier' : AdaBoostClassifier(random_state=0),\n",
    "    'GradientBoostingClassifier' : GradientBoostingClassifier(random_state=0),\n",
    "    'ExtraTreesClassifier' : ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "    'RandomForestClassifier' : RandomForestClassifier(n_estimators=100, random_state=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read training data\n",
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 371 entries, 0 to 370\n",
      "Data columns (total 7 columns):\n",
      "id               371 non-null int64\n",
      "bone_length      371 non-null float64\n",
      "rotting_flesh    371 non-null float64\n",
      "hair_length      371 non-null float64\n",
      "has_soul         371 non-null float64\n",
      "color            371 non-null object\n",
      "type             371 non-null object\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 20.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bone_length</th>\n",
       "      <th>rotting_flesh</th>\n",
       "      <th>hair_length</th>\n",
       "      <th>has_soul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>443.676550</td>\n",
       "      <td>0.434160</td>\n",
       "      <td>0.506848</td>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.471392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>263.222489</td>\n",
       "      <td>0.132833</td>\n",
       "      <td>0.146358</td>\n",
       "      <td>0.169902</td>\n",
       "      <td>0.176129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061032</td>\n",
       "      <td>0.095687</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>205.500000</td>\n",
       "      <td>0.340006</td>\n",
       "      <td>0.414812</td>\n",
       "      <td>0.407428</td>\n",
       "      <td>0.348002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.434891</td>\n",
       "      <td>0.501552</td>\n",
       "      <td>0.538642</td>\n",
       "      <td>0.466372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>678.500000</td>\n",
       "      <td>0.517223</td>\n",
       "      <td>0.603977</td>\n",
       "      <td>0.647244</td>\n",
       "      <td>0.600610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>897.000000</td>\n",
       "      <td>0.817001</td>\n",
       "      <td>0.932466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  bone_length  rotting_flesh  hair_length    has_soul\n",
       "count  371.000000   371.000000     371.000000   371.000000  371.000000\n",
       "mean   443.676550     0.434160       0.506848     0.529114    0.471392\n",
       "std    263.222489     0.132833       0.146358     0.169902    0.176129\n",
       "min      0.000000     0.061032       0.095687     0.134600    0.009402\n",
       "25%    205.500000     0.340006       0.414812     0.407428    0.348002\n",
       "50%    458.000000     0.434891       0.501552     0.538642    0.466372\n",
       "75%    678.500000     0.517223       0.603977     0.647244    0.600610\n",
       "max    897.000000     0.817001       0.932466     1.000000    0.935721"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bone_length</th>\n",
       "      <th>rotting_flesh</th>\n",
       "      <th>hair_length</th>\n",
       "      <th>has_soul</th>\n",
       "      <th>color</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.350839</td>\n",
       "      <td>0.465761</td>\n",
       "      <td>0.781142</td>\n",
       "      <td>clear</td>\n",
       "      <td>Ghoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.575560</td>\n",
       "      <td>0.425868</td>\n",
       "      <td>0.531401</td>\n",
       "      <td>0.439899</td>\n",
       "      <td>green</td>\n",
       "      <td>Goblin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.467875</td>\n",
       "      <td>0.354330</td>\n",
       "      <td>0.811616</td>\n",
       "      <td>0.791225</td>\n",
       "      <td>black</td>\n",
       "      <td>Ghoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.776652</td>\n",
       "      <td>0.508723</td>\n",
       "      <td>0.636766</td>\n",
       "      <td>0.884464</td>\n",
       "      <td>black</td>\n",
       "      <td>Ghoul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.566117</td>\n",
       "      <td>0.875862</td>\n",
       "      <td>0.418594</td>\n",
       "      <td>0.636438</td>\n",
       "      <td>green</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bone_length  rotting_flesh  hair_length  has_soul  color    type\n",
       "0   0     0.354512       0.350839     0.465761  0.781142  clear   Ghoul\n",
       "1   1     0.575560       0.425868     0.531401  0.439899  green  Goblin\n",
       "2   2     0.467875       0.354330     0.811616  0.791225  black   Ghoul\n",
       "3   4     0.776652       0.508723     0.636766  0.884464  black   Ghoul\n",
       "4   5     0.566117       0.875862     0.418594  0.636438  green   Ghost"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get dummy color features\n",
    "train = train.join(pd.get_dummies(train.color))\n",
    "\n",
    "# create empty list to hold combinations of colors\n",
    "c = []\n",
    "\n",
    "# create combinations of color features (min 2, max nunique colors - 1)\n",
    "for i in range(2, train.color.nunique()):\n",
    "    els = [list(x) for x in combinations(train.color.unique(), i)]\n",
    "    c.extend(els)\n",
    "\n",
    "# sum the combinations and add new column to train\n",
    "for i in c:\n",
    "    train['_'.join(i)] = train[i].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Deviations From Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# flag bone_length within/outside +/-1 std of mean\n",
    "train['bone_length_std1'] = train.bone_length.apply(\n",
    "    lambda x : -1 if x < (train.bone_length.mean() - train.bone_length.std())\n",
    "    else 1 if x > (train.bone_length.mean() + train.bone_length.std())\n",
    "    else 0,\n",
    ")\n",
    "\n",
    "# flag rotting_flesh within/outside +/-1 std of mean\n",
    "train['rotting_flesh_std1'] = train.rotting_flesh.apply(\n",
    "    lambda x : -1 if x < (train.rotting_flesh.mean() - train.rotting_flesh.std())\n",
    "    else 1 if x > (train.rotting_flesh.mean() + train.rotting_flesh.std())\n",
    "    else 0,\n",
    ")\n",
    "\n",
    "# flag hair_length within/outside +/-1 std of mean\n",
    "train['hair_length_std1'] = train.hair_length.apply(\n",
    "    lambda x : -1 if x < (train.hair_length.mean() - train.hair_length.std())\n",
    "    else 1 if x > (train.hair_length.mean() + train.hair_length.std())\n",
    "    else 0,\n",
    ")\n",
    "\n",
    "# flag has_soul within/outside +/-1 std of mean\n",
    "train['has_soul_std1'] = train.has_soul.apply(\n",
    "    lambda x : -1 if x < (train.has_soul.mean() - train.has_soul.std())\n",
    "    else 1 if x > (train.has_soul.mean() + train.has_soul.std())\n",
    "    else 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define poly\n",
    "poly = PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)\n",
    "\n",
    "# fit_transform train data\n",
    "poly_numeric = poly.fit_transform(train.drop(columns=[\n",
    "    'id',\n",
    "    'type',\n",
    "    'color',\n",
    "]))\n",
    "\n",
    "# redefine train with new poly features\n",
    "train = train.loc[:, [\n",
    "    'id',\n",
    "    'type',\n",
    "    'color',\n",
    "]].join(pd.DataFrame(\n",
    "    data=poly_numeric,\n",
    "    columns=poly.get_feature_names(train.drop(columns=[\n",
    "        'id',\n",
    "        'type',\n",
    "        'color',\n",
    "    ]).columns.tolist())\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# select X features\n",
    "X = train.drop(columns=[\n",
    "    'id',\n",
    "    'color',\n",
    "    'type',\n",
    "])\n",
    "\n",
    "# select y for training\n",
    "y = train.type\n",
    "\n",
    "# define scaler\n",
    "scaler = MinMaxScaler()\n",
    "rscaler = RobustScaler()\n",
    "\n",
    "# scale X\n",
    "X_ = pd.DataFrame(\n",
    "    data=scaler.fit_transform(X),\n",
    "    index=X.index,\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "X_r = pd.DataFrame(\n",
    "    data=rscaler.fit_transform(X),\n",
    "    index=X.index,\n",
    "    columns=X.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# redefine variance threshold (in case it wasn't previously)\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "# redefine X_ based on vt\n",
    "X_ = pd.DataFrame(\n",
    "    data=vt.fit_transform(X_),\n",
    "    index=X_.index,\n",
    "    columns=X_.columns[vt.get_support()]\n",
    ")\n",
    "\n",
    "# redefine X_r based on vt\n",
    "X_r = pd.DataFrame(\n",
    "    data=vt.fit_transform(X_r),\n",
    "    index=X_r.index,\n",
    "    columns=X_r.columns[vt.get_support()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Percentile Selection\n",
    "##### Using [Mutual Information](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# define selector\n",
    "selector = SelectPercentile(\n",
    "    score_func=mutual_info_classif,\n",
    "    percentile=10\n",
    ")\n",
    "\n",
    "# keep top 10 percent of features\n",
    "X_ = pd.DataFrame(\n",
    "    data=selector.fit_transform(X_, y),\n",
    "    index=X_.index,\n",
    "    columns=X_.columns[selector.get_support()]\n",
    ")\n",
    "\n",
    "# keep top 10 percent of features\n",
    "X_r = pd.DataFrame(\n",
    "    data=selector.fit_transform(X_r, y),\n",
    "    index=X_r.index,\n",
    "    columns=X_r.columns[selector.get_support()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = {}\n",
    "\n",
    "for k,v in ensembles.items():\n",
    "    fi[k] = v.fit(X_, y).feature_importances_\n",
    "\n",
    "fi = pd.DataFrame.from_dict(fi, orient='index', columns=X_.columns)\n",
    "\n",
    "fi.sort_values(fi.columns.tolist(), ascending=False, inplace=True)\n",
    "fi.sort_values(fi.index.tolist(), axis=1, ascending=False, inplace=True)\n",
    "\n",
    "fi.style.highlight_max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = {}\n",
    "\n",
    "for k,v in ensembles.items():\n",
    "    fi[k] = v.fit(X_r, y).feature_importances_\n",
    "\n",
    "fi = pd.DataFrame.from_dict(fi, orient='index', columns=X_r.columns)\n",
    "\n",
    "fi.sort_values(fi.columns.tolist(), ascending=False, inplace=True)\n",
    "fi.sort_values(fi.index.tolist(), axis=1, ascending=False, inplace=True)\n",
    "\n",
    "fi.style.highlight_max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top n per FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top features per fi-algorithm\n",
    "n = 1\n",
    "\n",
    "sns.pairplot(\n",
    "    data=X.join(y),\n",
    "    hue='type',\n",
    "    vars=list(set(fi.iloc[0].sort_values(ascending=False).head(n).index.tolist() +\\\n",
    "                  fi.iloc[1].sort_values(ascending=False).head(n).index.tolist() +\\\n",
    "                  fi.iloc[2].sort_values(ascending=False).head(n).index.tolist() +\\\n",
    "                  fi.iloc[3].sort_values(ascending=False).head(n).index.tolist()))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important feature from all three ensemble algorithms is `hair_length`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X_r, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for k,v in classifiers.items():\n",
    "    \n",
    "    print(k)\n",
    "    \n",
    "    cv = cross_validate(\n",
    "        estimator=v,\n",
    "        X=train_x,\n",
    "        y=train_y,\n",
    "        cv=10\n",
    "    )\n",
    "    \n",
    "    cv = cv['test_score']\n",
    "    \n",
    "    results[k] = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector 10\n",
    "pd.DataFrame.from_dict(results, orient='columns').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoostClassifier_g = GridSearchCV(\n",
    "    estimator=AdaBoostClassifier(),\n",
    "    param_grid={\n",
    "        'n_estimators' : np.arange(50, 250, 5),\n",
    "        'learning_rate' : np.arange(1e-2, 1e1, 1e-1),\n",
    "        'algorithm' : ['SAMME', 'SAMME.R'],\n",
    "        'random_state' : [0]\n",
    "    },\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "AdaBoostClassifier_g.fit(train_x, train_y)\n",
    "\n",
    "print(f\"AdaBoostClassifier_g.best_score_: {AdaBoostClassifier_g.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    estimator=AdaBoostClassifier_g.best_estimator_,\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "print(pd.Series(scores).describe())\n",
    "\n",
    "pd.Series(scores).plot.kde();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ExtraTreesClassifier_g = GridSearchCV(\n",
    "    estimator=ExtraTreesClassifier(),\n",
    "    param_grid={\n",
    "        'n_estimators' : np.arange(50, 250, 5),\n",
    "        'learning_rate' : np.arange(1e-2, 1e1, 1e-1),\n",
    "        'algorithm' : ['SAMME', 'SAMME.R'],\n",
    "        'random_state' : [0]\n",
    "    },\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "AdaBoostClassifier_g.fit(train_x, train_y)\n",
    "\n",
    "print(f\"AdaBoostClassifier_g.best_score_: {AdaBoostClassifier_g.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LogisticRegression_g = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid={\n",
    "        'random_state' : [0],\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : np.arange(1e-2, 1e1, 1e-1),\n",
    "        'fit_intercept' : [True],\n",
    "        'max_iter' : [200],\n",
    "        'solver' : ['liblinear'],\n",
    "        'multi_class' : ['auto'],\n",
    "    },\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "LogisticRegression_g.fit(train_x, train_y)\n",
    "\n",
    "print(f\"LogisticRegression_g.best_score_: {LogisticRegression_g.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    estimator=LogisticRegression_g.best_estimator_,\n",
    "    X=train_x,\n",
    "    y=train_y,\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "print(pd.Series(scores).describe())\n",
    "\n",
    "pd.Series(scores).plot.kde();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(\n",
    "    y_true=test_y,\n",
    "    y_pred=LogisticRegression_g.best_estimator_.predict(test_x),\n",
    "    output_dict=True\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
